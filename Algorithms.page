TODO merge in notes from CS170

TODO

- basics
  - the chinese remainder theorem (really an algo)
  - the euclidean algorithm
  - gaussian elimination
  - linear programming
  - primality testing
  - fast matrix product
  - tsp
  - integer factoring
- combinatorial optimization
  - minimum spanning tree
  - shortest path in graphs
  - for-fulkerson max-flow algorithm
  - gale-shapley stable marriage
  - general matching in graphs
- randomized algos
  - primality testing
  - volume of convex bodies
  - counting matchings
  - min-cut of graphs
  - string matching
  - hashing
- heuristic algos
  - local search
  - shotgun sequencing algorithm
  - simulated annealing
- real-world impact
  - fast fourier transform
  - rsa encryption
  - miller-rabin primality test
  - reed-solomon codes
  - lempel-ziv compression
  - page rank of google
  - consistent hashing of akamai
  - viterbi and hidden markov models
  - smith-waterman
  - spectral low rank approximation algorithms
  - binary decision diagrams
- info theory
  - digital fountain codes
  - cdma
  - compressive sensing of images
- <http://rjlipton.wordpress.com/2009/10/27/highlights-of-focs-theory-day/>

misc terms

- _binary decision diagram (BDD)_: binary tree representation of truth table;
  each layer switches on one input

core concepts

- TODO: Range counting, predecessor, voronoi diagrams, dynamic optimality, planar point location, nearest neighbor, partial sums, connectivity
- skim adv algos
- <http://mybiasedcoin.blogspot.com/2009/10/core-tcs.html>

hash tables

- direct chaining: list per bucket; optional move-to-front heuristic
- linear scanning aka open addressing: try other slots
  - try $h$, $h+1$, $h+2$, ...
  - try $h_1$, $h_2$, $h_3$, ...
- cuckoo hashing: $k$ (usu. 2) hash fn's
  - insert: into one of the 2 locs, displacing any resident and repeat the
    insertion of the resident, possibly evicting multiple keys
  - lookup: inspect 2 locs
  - inserts succeed in expected const time, even amortizing table rebuilds
    (growths), as long as load factor <50%; with 3 fn's, up to <91% load
  - also considering $n$-way tables; with 2 keys per bucket, up to <80% load
  - much faster than chained hashing for small, cache-resident hash tables on
    modern processors
  - $n$-way buckets faster than conventional methods for large tables

hash functions

- _rotating hashes_: for open addressing, avoid computing a bunch of different
  hash functions; just compute one long hash value and apply sliding window on
  it to get a bunch of shorter hash values

bloom filter

- TODO

prime sieve

  given n, return all primes up through n
  isprime = [true] * n
  for i in [2..n]
    for j in [2i, 3i, ..., n]
      isprime[j] = false
  return [ i for i in [2..n] where isprime[i] ]

gcd

  more concise (yay mod operator):
  gcd(a,b) =
    if b = 0, a
    else,     gcd(a, b % a)

  explicit:
  gcd(a,b) =
    if b = 0, a
    if a < b, gcd(b, a)      // swap
    else,     gcd(a, b % a)

self-balancing binary search trees

- red-black
  - leaf nodes don't contain data; sometimes use single sentinal
  - root, leaf nodes are black
  - red nodes have black children
  - every simple path from any node to any descendant leaf contains same number
    of black nodes
- AVL
- splay

string search

- knuth morris pratt
- boyer-moore
- boyer-moore-horspool

hashing

- locality sensitive hashing
- perfect hashing
- universal hashing
- linear probing, linear hashing

spatial indexing

- quadtree: 4-ary tree (child per quadrant)
- geohashing: treat each quadtree as trie, and address the quadrants as 00, 01,
  10, and 11; then leaves are `00 11 01 10 00`
  - to query region intersection, can just choose leaves for tightest bound,
    but that's slow/numerous
  - instead, specify max number of regions, then recursively choose the
    quadrant that when subdivided will remove the most area while staying under
    max
  - visit selected areas in "Z" order; this limits the continuity
- hilbert curves: "U" order; better locality behavior [for convex hulls?]
  - a type of 1D fractal known as a _space-filling curve_
  - can translate (x,y) to hilbert curve pos
- <http://blog.notdot.net/2009/11/Damn-Cool-Algorithms-Spatial-indexing-with-Quadtrees-and-Hilbert-Curves>

bin packing

- NP-hard
- items of diff sizes must be packed into identical bins; minimize # bins
- formally: given bin size $V$ and item sizes $a_1,\dots,a_n$, find int $B$ and
  $B$-partition $S_1 \cup \dots \cups S_B$ of ${1,\dots,n}$ such that $\sum_{i
  \in S_k} a_i \le V$ for all $k \in 1,\dots,B$

integer linear programming

- maximize $\mathbf{c}^T \mathbf{x}$ subject to $A \mathbf{x} \le \mathbf{b}$

randomized
==========

- reservoir sampling: sample $n$ elts from stream of unknown len in 1 pass
  - keep buffer (_reservoir_) of $n$ elts, where elts are $x_i$
  - $\forall x_i, i>n$, with prob $n/i$ replace random buffered elt with $x_i$
  - prob $n/i$ is prob of no combination of $n$ elts containing $x_i$ (or any
    particular elt in a set of $i$ elts)
- weighted reservoir sampling: each elt has weight
  - maintain total seen weight and total reservoir weight

sort
====

TODO heap, insertion, selection, bubble, radix, quick

in-place quicksort (c.a.r. hoare)

- select a pivot, possibly doing so using sampling
- rather than building lists less/equal/greater, walk the list from both ends
  and swap as necessary (to construct sublists in-place)

timsort

- adaptive, stable, natural mergesort; hybrid with insertion sort
- supernatural perf on many kinds of partially ordered/reversed arrays
  - less than lg(N!) cmp's needed; few as N-1
  - as fast as Python's previous highly tuned samplesort hybrid on random arrays
- pseudocode: TODO
- use
  - python's default list.sort
  - java 7's new Arrays.sort
- <http://svn.python.org/projects/python/trunk/Objects/listsort.txt>
- <http://en.wikipedia.org/wiki/Timsort>
- <http://stackoverflow.com/questions/1733073/grokking-timsort>

dynamic programming
===================

dynamic time-warping

edit distance

- levenshtein distance: the standard way of measuring distance; ins/del/upd
  - damerau-levenshtein: also transposition of two chars
- hamming distance: considers only substitutions in same-length strings

subsequence sum

- given $x_i$, $A_i$ is max subsequence sum up to and including $x_i$

  $$A_i = \max{ A_{i-1}, 0 } + x_i$$

compression
===========

- huffman coding
  - variable length coding: more freq symbols given shorter codes
- LZ77
  - sliding window compression, replacing strings with backrefs
    ((length,offset) pairs)
  - strings must be within window size apart
- LZ78: like LZ77 but looking forward as well; less popular
- lempel-ziv-welch (LZW): patent-encumbered modification of LZ78
- deflate
  - intended to be patent-unencumbered replacement for LZW
  - LZ77 then huffman coding, but uses one huffman tree for char literals and
    length codes, and another for backwards offsets
- zip
  - permits multiple compression algos, but deflate dominant
  - can take collections of files, but compresses each individually, so can't
    exploit redundancy across files
- LZMA: lempel-ziv markov chain
  - used in 7z
- burrows-wheeler transform (BWT)
  - sort all rotations of a string (padded with start and end) and take last
    col
  - reversible: last col gives all chars; sort to get first col; last and first
    give all pairs of successive chars
- bzip2: BWT + MTF transform + Huffman coding; parallelizable; slower than gzip
  - move-to-front (MTF) transform: decrease entropy; usu useful only after BWT
- prediction by partial matching (PPM): smaller/slower than bzip2
- lempel-ziv-oberhumer (LZO): very fast decompression
  - block-based (parallelizable)
  - similar compression speed as deflate
  - added to hadoop by twitter
- zippy: google's fast compression algo
  - zippy: 300MB/s encode, 600MB/s decode, 2-4X compression
  - gzip: 25MB/s encode, 200MB/s decode, 4-6X compression
  - <http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf>
- implementations:
  - gzip: uses zlib
  - zlib: deflate; compresses single files (freq. tar); not parallelizable

[On Reducing the Size of Compressed Javascript (by up to 20%)](http://timepedia.blogspot.com/2009/08/on-reducing-size-of-compressed.html)

- browser only supports gzip; implementing lzma/ppm in js too slow
- gzip = LZ77 + huffman; huffman uses separate huffman tree for backwards
  offset
  - arrange for the backwards offsets to be the same
- sort functions to cluster by similarity, eg tf-idf, edit distance
  - impl: use edit distance, then recursively combine best-matching pairs
- other tricks:
  - larger-base charset for var renames
  - rename from bottom-up scopes to reuse vars
  - stable ordering of renames (so always get f(a,b,c))

high-perf linear algebra
========================

TODO singular value decomposition (SVD)

- many apps in signal processing and statistics
- important factorization of rectangular real or complex matrix

TODO fast-fourier transform (FFT)

- compute (inverse) discrete FT
- FFT on columns
- multiply by twiddle factors
- FFT on rows
- transposes
- butterfly diagram: used to describe FFT; portion of compute that combines
  smaller DFTs into larger DFT

TODO parallel HPC algorithms
